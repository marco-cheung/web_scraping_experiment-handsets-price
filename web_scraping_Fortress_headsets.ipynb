{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping with BeautifulSoup and Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites:\n",
    "\n",
    "#### python 3.6\n",
    "#### chromedriver <-- a Chrome browser engine to initialize Chrome for automated running of Selenium-related script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prerequisites\n",
    "\n",
    "import requests  #for handling HTTP requests\n",
    "from bs4 import BeautifulSoup  #for parsing HTML\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define website url which I am going to scrape\n",
    "url = \"https://www.fortress.com.hk/en/shop/mobile-and-communications/smartphones/c/5\"\n",
    "base_url = \"https://www.fortress.com.hk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new Chrome session\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(options = chrome_options)\n",
    "driver.implicitly_wait(5) #tell WebDriver to elapse 5 seconds when trying to find any element (or elements) not immediately available\n",
    "\n",
    "#Direct the driver to the URL we want to scrape\n",
    "driver.get(url)\n",
    "\n",
    "#tell WebDriver to elapse 5 seconds when trying to find any element (or elements) not immediately available\n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There's no more products at the bottom of this page.\n"
     ]
    }
   ],
   "source": [
    "#After opening the url above, Selenium browser automator will search and click \"View More\" button\n",
    "#to display more products. If no such button element, then ignore this exceptional case\n",
    "while True:\n",
    "    try:\n",
    "        view_button = driver.find_element_by_link_text(\"View More\")\n",
    "        view_button.click()\n",
    "        time.sleep(3)\n",
    "    except Exception:\n",
    "        print (\"There's no more products at the bottom of this page.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to build and maintain an efficient automated web scraper, firstly we need to understand the structure of the website, e.g. html source code, XPath, etc.\n",
    "#### (p.s. click F12 to inspect the element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We finally fetched 94 products URLs.\n"
     ]
    }
   ],
   "source": [
    "#Gather all products URLs on the web page at once\n",
    "headsets_containers = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "products_urls = []\n",
    "for a in headsets_containers.find_all('a', class_ = \"thumb gtmProductImpressions\"): \n",
    "    if a.text: \n",
    "        products_urls.append(base_url + a['href'])\n",
    "\n",
    "products_urls = list(np.unique(products_urls))\n",
    "\n",
    "print(\"We finally fetched \" + str(len(products_urls)) + \" products URLs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview first 5 product urls\n",
    "#products_urls[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define field of product details\n",
    "brand = []\n",
    "product_name = []\n",
    "color = [] #different colour options may result in different prices\n",
    "capacity_spec = [] #different capacity options may result in different prices\n",
    "RRP = []   #recommended retail price\n",
    "selling_price = []\n",
    "free_gift = []\n",
    "product_url = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping is completed.\n",
      "Wall time: 48min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for i in products_urls:\n",
    "    driver.get(i)\n",
    "         \n",
    "    try:\n",
    "        #find color option(s)\n",
    "        colour = driver.find_elements_by_xpath('//input[contains(@name, \"Colour\")]')\n",
    "   \n",
    "        for x in colour:\n",
    "            driver.execute_script(\"arguments[0].click()\", x)\n",
    "            #Give the javascript time to render\n",
    "            time.sleep(3)\n",
    "\n",
    "            #find capacity option(s)\n",
    "            capacity = driver.find_elements_by_xpath('//input[contains(@name, \"Capacity\")]')\n",
    "        \n",
    "            for elem in capacity:\n",
    "                if elem.is_enabled():\n",
    "                    driver.execute_script(\"arguments[0].click()\", elem)\n",
    "                    time.sleep(3)\n",
    "                \n",
    "                    #Use driver.page_source to get the HTML as it appears after javascript has rendered it\n",
    "                    page_source = driver.page_source\n",
    "                \n",
    "                    #Use a parser on the returned HTML\n",
    "                    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "                    time.sleep(3)\n",
    "                \n",
    "                    #scrap capacity\n",
    "                    capacity_spec.append(elem.get_attribute('value')) \n",
    "            \n",
    "                    #scrap brand\n",
    "                    brand.append(soup.find(\"span\", itemprop = \"brand\").text.upper())\n",
    "                \n",
    "                    #scrap product name\n",
    "                    product_name.append(soup.find(\"h1\", class_ = \"h2 name\").text.upper())\n",
    "                \n",
    "                    #scrap colour\n",
    "                    color.append(x.get_attribute('value'))\n",
    "                \n",
    "                    #refresh the parser\n",
    "                    page_source = driver.page_source\n",
    "                    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "                \n",
    "                    #scrap RRP\n",
    "                    RRP0 = soup.find(\"div\", itemprop = \"offers\").text.replace('RRP: ','').replace('HK$','').replace(',','')\n",
    "                    RRP.append(re.findall('\\d+|$', RRP0)[0])\n",
    "                \n",
    "                    #scrap free gift titles(s)\n",
    "                    #free_gift.append(soup.find(\"div\", class_ = \"gifts\").text.strip().replace(\"\\n\",\" \").replace(\"       \",'// '))\n",
    "                \n",
    "                    #scrap product_url\n",
    "                    product_url.append(i)\n",
    "                \n",
    "                    #scrap special price (final selling price)\n",
    "                    if soup.find(\"span\", itemprop = \"offers price\") is not None:\n",
    "                        selling_price.append(soup.find(\"span\", itemprop = \"offers price\").text.replace('HK$','').replace(',',''))\n",
    "                    else:\n",
    "                        selling_price.append(RRP0)\n",
    "        \n",
    "            #alternative handling if capacity option is not found in the page                \n",
    "            if len(capacity) == 0:\n",
    "                page_source = driver.page_source\n",
    "                soup = BeautifulSoup(page_source, 'html.parser')\n",
    "                time.sleep(3)\n",
    "                \n",
    "                #scrap capacity\n",
    "                capacity_spec.append('')\n",
    "            \n",
    "                #scrap brand\n",
    "                brand.append(soup.find(\"span\", itemprop = \"brand\").text.upper())\n",
    "            \n",
    "                #scrap product name\n",
    "                product_name.append(soup.find(\"h1\", class_ = \"h2 name\").text.upper())\n",
    "                \n",
    "                #scrap colour\n",
    "                color.append(x.get_attribute('value'))\n",
    "            \n",
    "                page_source = driver.page_source\n",
    "                soup = BeautifulSoup(page_source, 'html.parser')\n",
    "            \n",
    "                #scrap RRP\n",
    "                RRP0 = soup.find(\"div\", itemprop = \"offers\").text.replace('RRP: ','').replace('HK$','').replace(',','')\n",
    "                RRP.append(re.findall('\\d+|$', RRP0)[0])\n",
    "                \n",
    "                #scrap free gift title(s)            \n",
    "                #free_gift.append(soup.find(\"div\", class_ = \"gifts\").text.strip().replace(\"\\n\",\" \").replace(\"       \",'// '))\n",
    "            \n",
    "                #scrap product url\n",
    "                product_url.append(i)\n",
    "            \n",
    "                #scrap special price (final selling price)\n",
    "                if soup.find(\"span\", itemprop = \"offers price\") is not None:\n",
    "                    selling_price.append(soup.find(\"span\", itemprop = \"offers price\").text.replace('HK$','').replace(',',''))\n",
    "                else:\n",
    "                    selling_price.append(RRP0)\n",
    "                \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "driver.close()\n",
    "print (\"Scraping is completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To zip 8 lists together and then construct dataframe\n",
    "list_of_tuples = list(zip(brand, product_name, color, capacity_spec, RRP, selling_price, product_url))\n",
    "df = pd.DataFrame(list_of_tuples, columns = ['Brand', 'Product Name', 'Colour', 'Capacity', 'RRP', 'Selling Price', 'Product URL'])\n",
    "\n",
    "#Indicate \"Fortress\" as data source\n",
    "df.insert(0, 'Source', 'Fortress')\n",
    "\n",
    "#Populate current date in new column for visualizing time-series data\n",
    "df['Date'] = pd.to_datetime('today').date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To convert all characters to upper case and remove all parentheses and stuff within for Product Name\n",
    "#Example: 'HUAWEI MATE20 PRO (6GB/128GB) (BK)' => 'HUAWEI MATE20 PRO'\n",
    "df['Product Name'] = df['Product Name'].str.replace(r\"\\(.*\\)\",\"\").str.strip()\n",
    "df['Product Name'] = df['Product Name'].str.replace('-',\"\").str.strip() \n",
    "df['Product Name'] = df['Product Name'].str.replace('SMARTPHONE','').str.strip()\n",
    "df['Product Name'] = df['Product Name'].str.replace('VERSION','').str.strip()\n",
    "df['Product Name'] = df['Product Name'].str.replace('GAMING','').str.strip()\n",
    "df['Product Name'] = df['Product Name'].str.replace('MOBILE PHONE','').str.strip()\n",
    "df['Product Name'] = df['Product Name'].str.replace('GALAXY','').str.strip()\n",
    "df['Product Name'] = df['Product Name'].str.replace('VIEW20','VIEW 20').str.strip()\n",
    "df['Product Name'] = df['Product Name'].str.replace(' - HONG KONG','').str.strip()  #Trim all spaces from the text string except for single spaces between words\n",
    "\n",
    "#Create dictionary for special handling of (Nokia) product name\n",
    "dict1 = {\n",
    "    \"NOKIA 8.1 128GB\": \"NOKIA 8.1 (128GB)\",\n",
    "    \"NOKIA 8.1\": \"NOKIA 8.1 (64GB)\",\n",
    "    \"NOKIA 3.2\": \"NOKIA 3.2 (32GB)\",\n",
    "    \"NOKIA 4.2\": \"NOKIA 4.2 (32GB)\",\n",
    "    \"NOKIA 5.1 PLUS\": \"NOKIA 5.1 PLUS (32GB)\",\n",
    "    \"NOKIA NOKIA 9 PUREVIEW\": \"NOKIA 9 PUREVIEW (128GB)\",\n",
    "    \"NOKIA 2720 FLIP\": \"NOKIA 2720\",\n",
    "    \"NOKIA 7.2\": \"NOKIA 7.2 (128GB)\",\n",
    "    \"SONY XPERIA 5\": \"SONY XPERIA 5 (128GB)\"\n",
    "}\n",
    "\n",
    "# Remap the values of the dataframe \n",
    "df.replace({'Product Name': dict1}, inplace=True)\n",
    "\n",
    "#Remove year (e.g. 2018, 2019)\n",
    "year = ['2017','2018','2019','2020','2021','2022','2023','2024']\n",
    "df['Product Name'] = df['Product Name'].str.replace('|'.join([re.escape(s) for s in year]), '')\n",
    "df['Product Name'] = df['Product Name'].str.strip()\n",
    "\n",
    "#To convert all characters to upper case and remove all special characters, parentheses and stuff within for 'Colour'\n",
    "df['Colour'] = df['Colour'].str.upper()\n",
    "df['Colour'] = [re.sub('[^A-Z0-9 \\n]', '', x) for x in df['Colour']]\n",
    "df['Colour'] = df['Colour'].str.replace('SLIVER','SILVER')\n",
    "df['Colour'] = df['Colour'].str.strip()\n",
    "\n",
    "#To remove all whitespace and add parenthesis for 'Capacity'\n",
    "df['Capacity'] = df['Capacity'].str.replace(' ','').str.strip()\n",
    "df['Capacity'] = [''.join('(' + item + ')').replace('()','') for item in df['Capacity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of unique brand\n",
    "unique_brand = df['Brand'].unique().tolist()\n",
    "\n",
    "#Problem found: in some cases, product name does not include brand (e.g.'GALAXY A8+')\n",
    "#Solution: Align product name display (i.e. brand + name)\n",
    "#1. remove brand name in product name first\n",
    "p = re.compile('|'.join(map(re.escape, unique_brand)))\n",
    "df['Product Name'] = [p.sub('', text).strip() for text in df['Product Name']]\n",
    "\n",
    "#2. concatenate Brand Name and product name to align product name format\n",
    "df['Product Name'] = df['Brand'].map(str) + ' ' + df['Product Name'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, rename convention of Product Name = Product Name + Capacity (EXCEPT 'Nokia' mobile phone for easier mapping)\n",
    "exceptional_brand = 'NOKIA'\n",
    "\n",
    "for i in df['Product Name']:\n",
    "    if exceptional_brand not in i:\n",
    "        df['Name'] = df['Product Name'].str.cat(df['Capacity'],sep=\" \").str.strip()\n",
    "\n",
    "df.drop('Product Name', axis=1, inplace=True)\n",
    "df = df.rename({'Name': 'Product Name'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary for special handling of Samsung product name\n",
    "dict2 = {\n",
    "    \"SAMSUNG A60 (6GB)\": \"SAMSUNG A60 (128GB)\",   #wrongly marked by Fortress\n",
    "    \"SAMSUNG A80 (8GB)\": \"SAMSUNG A80 (128GB)\",   #wrongly marked by Fortress          \n",
    "    \"SAMSUNG A9\": \"SAMSUNG A9 (128GB)\"\n",
    "}\n",
    "\n",
    "# Remap the values of the dataframe \n",
    "df.replace({'Product Name': dict2}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finalize dataframe column order\n",
    "df = df[['Date', 'Source', 'Brand', 'Product Name', 'Colour', 'Capacity', 'RRP', 'Selling Price', 'Product URL']]\n",
    "\n",
    "df1 = df[['Date', 'Source', 'Brand', 'Product Name', 'RRP', 'Selling Price']]\n",
    "\n",
    "#Drop duplicates product and keep='first' to keep first of duplicates\n",
    "#In case one product is selling at different prices for different colours, then only keep first of duplicates for each product name\n",
    "#(i.e. given that most products are selling the same price for different colours)\n",
    "cleaned_df1 = df1.drop_duplicates(subset=['Product Name'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To write dataframe to new Excel file and append data to 'Aggregated_Fortress_headsets_offer.csv'\n",
    "CurrentDate = time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "root = 'Fortress'\n",
    "\n",
    "df.to_excel(root + '/' + CurrentDate + ' Fortress headsets offer' + '.xlsx', sheet_name = 'Fortress_headsets', index = False, encoding='utf-8-sig')\n",
    "\n",
    "#Stack the DataFrames on top of 'Aggregated_Fortress_headsets_offer.csv'\n",
    "cleaned_df1.to_csv('Aggregated_Fortress_headsets_offer.csv', index = False, header = False, mode='a', encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
